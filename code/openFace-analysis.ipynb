{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compute_fixation_stats(file_path, angle_threshold):\n",
    "    \n",
    "# Load OpenFace eye-tracking data (CSV file)\n",
    "    data = pd.read_csv(file_path, index_col = 0, delimiter=',')  # Replace 'openface_eye_tracking_data.csv' with your file path\n",
    "    data.columns = data.columns.str.strip()\n",
    "    # print(data.columns)\n",
    "\n",
    "    # Extract relevant columns from the dataset\n",
    "    time = data['unix']  # Timestamps\n",
    "    # time_intervals=np.diff(time)\n",
    "    gaze_x = data['gaze_0_x']  # Gaze direction in X-axis\n",
    "    gaze_y = data['gaze_0_y']  # Gaze direction in Y-axis\n",
    "    gaze_angle_x = np.degrees(data['gaze_angle_x'])  # Gaze direction in X-axis\n",
    "    gaze_angle_y = np.degrees(data['gaze_angle_y'])  # Gaze direction in Y-axis\n",
    "    velocity_x = np.diff(gaze_angle_x)/np.diff(time)\n",
    "    velocity_y = np.diff(gaze_angle_y)/np.diff(time)\n",
    "    velocity = np.sqrt(velocity_x**2 + velocity_y**2)\n",
    "    # acceleration_x = np.diff(velocity_x)/np.diff(time)\n",
    "    # acceleration_y = np.gradient(velocity_y)/np.diff(time)\n",
    "    # acceleration = np.sqrt(acceleration_x**2 + acceleration_y**2)\n",
    "    distances = np.sqrt(np.diff(gaze_angle_x)**2 + np.diff(gaze_angle_y)**2)\n",
    "    total_path_length=np.sum(distances)\n",
    "   \n",
    "\n",
    "    fixation_start = []\n",
    "    fixation_end = []\n",
    "    is_fixating = False\n",
    "    for index in range(1, len(data)):\n",
    "        # Check if the difference exceeds the threshold\n",
    "        if ((abs(gaze_angle_x.iloc[index] - gaze_angle_x.iloc[index - 1]) +\n",
    "                abs(gaze_angle_y.iloc[index] - gaze_angle_y.iloc[index - 1])) < angle_threshold):\n",
    "            if not is_fixating:\n",
    "                fixation_start.append(index)\n",
    "                is_fixating = True\n",
    "        else:\n",
    "            if is_fixating:\n",
    "                fixation_end.append(index - 1)\n",
    "                is_fixating = False\n",
    "\n",
    "    # If fixation was ongoing until the end of the data, add the last index as end point\n",
    "    if is_fixating:\n",
    "        fixation_end.append(len(data) - 1)\n",
    "         \n",
    "     # Calculate fixation durations\n",
    "    fixation_durations=[]\n",
    "    for start, end in zip(fixation_start, fixation_end):\n",
    "        duration = time.iloc[end] - time.iloc[start]\n",
    "        fixation_durations.append(duration)\n",
    "        \n",
    "\n",
    "    # Calculate average gaze direction during fixations\n",
    "    average_gaze_x = [gaze_x.loc[start:end].mean() for start, end in zip(fixation_start, fixation_end)]\n",
    "    average_gaze_y = [gaze_y.loc[start:end].mean() for start, end in zip(fixation_start, fixation_end)]\n",
    "    average_velocity = [np.mean(velocity[start:end+1]) for start, end in zip(fixation_start, fixation_end)]\n",
    "    # average_acceleration = [np.mean(acceleration[start:end+1]) for start, end in zip(fixation_start, fixation_end)]\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "    'Fixation_Start_Time': [time.iloc[start] for start, end, duration in zip(fixation_start, fixation_end, fixation_durations)\n",
    "                            if duration >= 100],\n",
    "    'Fixation_End_Time': [time.iloc[end] for start, end, duration in zip(fixation_start, fixation_end, fixation_durations)\n",
    "                          if duration >= 100],\n",
    "    'Fixation_Duration': [duration for start, end, duration in zip(fixation_start, fixation_end, fixation_durations)\n",
    "                          if duration >= 100],\n",
    "    'Average_Gaze_X': [avg_x for duration, avg_x in zip(fixation_durations, average_gaze_x) if duration >= 100],\n",
    "    'Average_Gaze_Y': [avg_y for duration, avg_y in zip(fixation_durations, average_gaze_y) if duration >= 100],\n",
    "    'Average_Velocity': [vel for duration, vel in zip(fixation_durations, average_velocity) if duration >= 100],\n",
    "    # 'Average_Acceleration': [acc for duration, acc in zip(fixation_durations, average_acceleration) if duration >= 100]\n",
    "    \n",
    "    })\n",
    "\n",
    "    # Save the results to a new CSV file\n",
    "    folder_path, file_name = os.path.split(file_path)\n",
    "    output_file_name =folder_path+'/output_files/'+ f'{file_name}_fixation.csv'\n",
    "    results_df.to_csv(output_file_name, index=False)  # Change 'eye_tracking_results.csv' to your desired file name\n",
    "    # print('Results saved to eye_tracking_results.csv')\n",
    "\n",
    "    # Compute additional statistics\n",
    "\n",
    "    # Filter fixation durations less than 100 ms\n",
    "    filtered_fixation_durations = [duration for duration in fixation_durations if duration >= 100]\n",
    "    filtered_average_velocity = [avg_vel for avg_vel, duration in zip(average_velocity, fixation_durations) if duration >= 100]\n",
    "    \n",
    "    # Compute additional statistics for valid fixations\n",
    "    mean_fixation_duration = np.mean(filtered_fixation_durations)\n",
    "    median_fixation_duration = np.median(filtered_fixation_durations)\n",
    "    std_fixation_duration = np.std(filtered_fixation_durations)\n",
    "    min_fixation_duration = np.min(filtered_fixation_durations)\n",
    "    max_fixation_duration = np.max(filtered_fixation_durations)\n",
    "    mean_average_velocity = np.mean(filtered_average_velocity)\n",
    "    median_average_velocity = np.median(filtered_average_velocity)\n",
    "    std_average_velocity = np.std(filtered_average_velocity)\n",
    "    min_average_velocity = np.min(filtered_average_velocity)\n",
    "    max_average_velocity = np.max(filtered_average_velocity)\n",
    "   \n",
    "      # Return fixation statistics\n",
    "    return {\n",
    "        'File_ID': os.path.splitext(os.path.basename(file_path))[0],\n",
    "        'Mean_fixation_duration': mean_fixation_duration,\n",
    "        'Median_fixation_duration': median_fixation_duration,\n",
    "        'Standard_Deviation_fixation_duration': std_fixation_duration,\n",
    "        'Minimum_fixation_duration': min_fixation_duration,\n",
    "        'Maximum_fixation_duration': max_fixation_duration,\n",
    "        'Mean_fixation_velocity': mean_average_velocity,\n",
    "        'Median_fixation_velocity': median_average_velocity,\n",
    "        'Standard_Deviation_fixation_velocity': std_average_velocity,\n",
    "        'Minimum_fixation_velocity': min_average_velocity,\n",
    "        'Maximum_fixation_velocity': max_average_velocity,\n",
    "        'Total_path_length':total_path_length\n",
    "    }\n",
    "    \n",
    "def detect_saccades(file_path, angle_threshold,velocity_threshold, acceleration_threshold):\n",
    "    \"\"\"\n",
    "    Detects saccades in the OpenFace dataset and computes statistics.\n",
    "\n",
    "    Åºarameters:\n",
    "        file_path (str): Path to the OpenFace dataset CSV file.\n",
    "        velocity_threshold (float): Threshold for velocity of gaze direction changes.\n",
    "        acceleration_threshold (float): Threshold for acceleration of gaze direction changes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing saccade data with timestamps and indices.\n",
    "        dict: Dictionary containing statistics for the detected saccades.\n",
    "    \"\"\"\n",
    "    # Load OpenFace CSV file containing facial landmark data\n",
    "    openface_data = pd.read_csv(file_path, index_col = 0, delimiter=',')  # Replace 'openface_eye_tracking_data.csv' with your file path\n",
    "    openface_data.columns = openface_data.columns.str.strip()\n",
    "    \n",
    "    # Extract timestamps\n",
    "    timestamps = openface_data['unix']\n",
    "    time_intervals=np.diff(timestamps)\n",
    "    \n",
    "    # gaze_x = openface_data['gaze_0_x']  # Gaze direction in X-axis\n",
    "    # gaze_y = openface_data['gaze_0_y']  # Gaze direction in Y-axis\n",
    "\n",
    "    # Extract gaze direction angles\n",
    "    gaze_angle_x =openface_data['gaze_angle_x']\n",
    "    gaze_angle_y =openface_data['gaze_angle_y']\n",
    "\n",
    "# Compute changes in gaze direction\n",
    "    gaze_angle_x_diff = np.diff(gaze_angle_x)\n",
    "    gaze_angle_y_diff = np.diff(gaze_angle_y)\n",
    "    gaze_angle_x_changes=np.abs(gaze_angle_x_diff)\n",
    "    gaze_angle_y_changes=np.abs(gaze_angle_y_diff)\n",
    "  # Compute velocity of gaze direction changes\n",
    "    velocity_x = np.diff(gaze_angle_x)/time_intervals\n",
    "    velocity_y = np.diff(gaze_angle_y)/time_intervals\n",
    "    velocity = np.sqrt(velocity_x**2 + velocity_y**2)\n",
    "    distances = np.sqrt(np.diff(gaze_angle_x)**2 + np.diff(gaze_angle_y)**2)\n",
    "  \n",
    "    # Compute acceleration of gaze direction changes\n",
    "    # acceleration_x = np.diff(velocity_x)/time_intervals\n",
    "    # acceleration_y = np.diff(velocity_y)/time_intervals\n",
    "    # acceleration = np.sqrt(acceleration_x**2 + acceleration_y**2)\n",
    "\n",
    "    # Convert velocity and acceleration thresholds to radians per second and radians per second squared\n",
    "    velocity_threshold_rad_per_sec = np.deg2rad(velocity_threshold)\n",
    "    acceleration_threshold_rad_per_sec_sq = np.deg2rad(acceleration_threshold)\n",
    "    # print(velocity_threshold_rad_per_sec)\n",
    "\n",
    "    # Detect saccades based on thresholds\n",
    "    # saccade_indices = np.where(\n",
    "    #     (velocity > velocity_threshold_rad_per_sec)    \n",
    "    # )[0]\n",
    "    \n",
    "    # combined_angle_changes = np.sqrt(gaze_angle_x_changes**2 + gaze_angle_y_changes**2)\n",
    "    # saccade_indices = np.where(combined_angle_changes > angle_threshold)[0] + 1\n",
    "    # # Classify saccades based on duration and velocity thresholds\n",
    "    # saccade_durations = np.diff(timestamps.iloc[saccade_indices])\n",
    "    \n",
    "    saccade_start = []\n",
    "    saccade_end = []\n",
    "    is_saccading = False\n",
    "    saccade_indices=[]\n",
    "\n",
    "    # Loop through the data starting from the second index\n",
    "    for index in range(1, len(openface_data)):\n",
    "        # Calculate combined change in gaze angles (x and y)\n",
    "        combined_angle_change = abs(gaze_angle_x.iloc[index] - gaze_angle_x.iloc[index - 1]) + abs(gaze_angle_y.iloc[index] - gaze_angle_y.iloc[index - 1])\n",
    "        \n",
    "        # Check if the combined change exceeds the threshold\n",
    "        if combined_angle_change > angle_threshold:\n",
    "            saccade_indices.append(index)\n",
    "            if not is_saccading:\n",
    "                saccade_start.append(index)\n",
    "            is_saccading = True\n",
    "        else:\n",
    "            if is_saccading:\n",
    "                saccade_end.append(index - 1)\n",
    "            is_saccading = False\n",
    "\n",
    "    # If a saccade was ongoing until the end of the data, add the last index as end point\n",
    "    if is_saccading:\n",
    "        saccade_end.append(len(openface_data) - 1)\n",
    "        \n",
    "    # Calculate saccade durations\n",
    "    saccade_durations = []\n",
    "    for start, end in zip(saccade_start, saccade_end):\n",
    "        duration = timestamps.iloc[end] - timestamps.iloc[start]\n",
    "        saccade_durations.append(duration) \n",
    "        \n",
    "    average_velocity = [np.mean(velocity[start:end+1]) for start, end in zip(saccade_start, saccade_end)]\n",
    "    min_velocity = [np.min(velocity[start:end+1]) for start, end in zip(saccade_start, saccade_end)]\n",
    "    max_velocity = [np.max(velocity[start:end+1]) for start, end in zip(saccade_start, saccade_end)]\n",
    "    path_length=[np.sum(distances[start:end+1]) for start, end in zip(saccade_start, saccade_end)]\n",
    "    \n",
    "    saccade_types = []\n",
    "    for duration in saccade_durations:\n",
    "        if duration < 20 and duration:\n",
    "            saccade_types.append('Micro')\n",
    "        elif duration >= 20 and duration < 80:\n",
    "            saccade_types.append('Standard')\n",
    "        elif duration >= 80 and duration <200:\n",
    "            saccade_types.append('Long')\n",
    "        else:\n",
    "            saccade_types.append('fixation')\n",
    "    #         # Ensure that saccade_types has the same length as saccade_indices\n",
    "    # while len(saccade_types) < len(saccade_durations):\n",
    "    #     saccade_types.append('fixation')\n",
    "    \n",
    "\n",
    "    # Save saccade data to a DataFrame\n",
    "    saccade_df = pd.DataFrame({\n",
    "        # 'Timestamp': timestamps.iloc[saccade_indices],\n",
    "        # 'Saccade_Index': saccade_indices,\n",
    "        'Saccade_Start': saccade_start,\n",
    "        'Saccade_End': saccade_end,\n",
    "        'Saccade_Type': saccade_types,\n",
    "        'Saccade_Duration': saccade_durations,\n",
    "        'Saccade_Mean_Velocity':average_velocity,\n",
    "        'Saccade_Min_Velocity':min_velocity,\n",
    "        'Saccade_Max_Velocity':max_velocity,\n",
    "        'Saccade_Path_Length:': path_length,\n",
    "            \n",
    "    })\n",
    "    \n",
    "    saccade_data=saccade_df[saccade_df['Saccade_Type'] != 'fixation']\n",
    "    \n",
    "\n",
    "    # Save the saccade data to a CSV file\n",
    "    folder_path, file_name = os.path.split(file_path)\n",
    "    output_file_name = folder_path + '/output_files/' + f'{file_name}_saccade_data.csv'\n",
    "    saccade_data.to_csv(output_file_name, index=False)\n",
    "    \n",
    "    saccade_stats = {}\n",
    "    # for saccade_type in set(saccade_data['Saccade_Type']):\n",
    "    #     type_indices = saccade_data[saccade_data['Saccade_Type'] == saccade_type].index\n",
    "    #     type_durations = [saccade_durations[i] for i in type_indices]  # Ensure valid indices\n",
    "    #     if type_durations:\n",
    "    #         mean_duration = np.mean(type_durations)\n",
    "    #         median_duration = np.median(type_durations)\n",
    "    #         std_duration = np.std(type_durations)\n",
    "    #         min_duration = np.min(type_durations)\n",
    "    #         max_duration = np.max(type_durations)\n",
    "\n",
    "    #         saccade_stats[f'Mean_Duration_{saccade_type}'] = mean_duration\n",
    "    #         saccade_stats[f'Median_Duration_{saccade_type}'] = median_duration\n",
    "    #         saccade_stats[f'Std_Duration_{saccade_type}'] = std_duration\n",
    "    #         saccade_stats[f'Min_Duration_{saccade_type}'] = min_duration\n",
    "    #         saccade_stats[f'Max_Duration_{saccade_type}'] = max_duration\n",
    "    if saccade_data.empty:\n",
    "        saccade_stats = {\n",
    "            'File_ID': os.path.splitext(os.path.basename(file_path))[0],\n",
    "            'Total_Micro': 0,\n",
    "            'Total_Standard': 0,\n",
    "            'Total_Long': 0,\n",
    "            'Total_All': 0,\n",
    "            'Max_Duration': np.nan,\n",
    "            'Min_Duration': np.nan,\n",
    "            'Mean_Duration': np.nan,\n",
    "            'Peak_Velocity': np.nan,\n",
    "            'Mean_Peak_Velocity': np.nan,\n",
    "            'Mean_Velocity': np.nan,\n",
    "            'Total_Path_Length': 0\n",
    "        }\n",
    "    else:\n",
    "\n",
    "        # Compute total counts for each saccade type\n",
    "        total_micro = saccade_data['Saccade_Type'].value_counts().get('Micro', 0)\n",
    "        total_standard = saccade_data['Saccade_Type'].value_counts().get('Standard', 0)\n",
    "        total_long = saccade_data['Saccade_Type'].value_counts().get('Long', 0)\n",
    "        total_all = len(saccade_data)\n",
    "        mean_duration= saccade_data['Saccade_Duration'].mean()\n",
    "        max_duration= saccade_data['Saccade_Duration'].max()\n",
    "        min_duration= saccade_data['Saccade_Duration'].min()\n",
    "\n",
    "        # Save saccade statistics to the dictionary\n",
    "        saccade_stats.update({\n",
    "            'File_ID': os.path.splitext(os.path.basename(file_path))[0],\n",
    "            'Total_Micro': total_micro,\n",
    "            'Total_Standard': total_standard,\n",
    "            'Total_Long': total_long,\n",
    "            'Total_All': total_all,\n",
    "            'Max_Duration': max_duration,\n",
    "            'Min_Duration': min_duration,\n",
    "            'Mean_Duration':mean_duration,\n",
    "            'Peak_Velocity': np.max(max_velocity),\n",
    "            'Mean_Peak_Velocity': np.mean(max_velocity),\n",
    "            'Mean_Velocity':np.mean(average_velocity),\n",
    "            'Total_Path_Length': np.sum(path_length)\n",
    "        })\n",
    "\n",
    "    return saccade_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/kc/596t6rmx1dn7bfyv5hfgmqm00000gn/T/ipykernel_900/3559044075.py:8: DtypeWarning: Columns (43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, index_col = 0, delimiter=',')  # Replace 'openface_eye_tracking_data.csv' with your file path\n",
      "/var/folders/kc/596t6rmx1dn7bfyv5hfgmqm00000gn/T/ipykernel_900/3559044075.py:130: DtypeWarning: Columns (43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  openface_data = pd.read_csv(file_path, index_col = 0, delimiter=',')  # Replace 'openface_eye_tracking_data.csv' with your file path\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/openai-projects/openai-guidelines/openai-env/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory containing CSV files\n",
    "directory = '/Users/openai-projects/openai-guidelines/openFace_files/of_files'\n",
    "\n",
    "# # Threshold for fixation detection\n",
    "# threshold = 200  # Adjust as needed\n",
    "\n",
    "# List to store computed statistics for all files\n",
    "stats_fixation_list = []\n",
    "stats_saccade_list = []\n",
    "\n",
    "# Loop through each CSV file in the directory\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        # Compute fixation statistics for the current file\n",
    "        stats = compute_fixation_stats(file_path, angle_threshold=1)\n",
    "        stats_saccade = detect_saccades(file_path, angle_threshold=0.080, velocity_threshold=5, acceleration_threshold=50)\n",
    "        \n",
    "        # Append statistics to the list\n",
    "        stats_fixation_list.append(stats)\n",
    "        stats_saccade_list.append(stats_saccade)\n",
    "\n",
    "# Create a DataFrame from the list of statistics\n",
    "stats_fixation_df = pd.DataFrame(stats_fixation_list)\n",
    "stats_saccade_df = pd.DataFrame(stats_saccade_list)\n",
    "\n",
    "# Modify the output file name with a suffix\n",
    "output_file_name_1 = 'fixation_statistics.csv'\n",
    "output_file_name_2 = 'saccade_statistics.csv'\n",
    "\n",
    "# Save the statistics to a CSV file with the modified name\n",
    "stats_fixation_df.to_csv(output_file_name_1, index=False)\n",
    "stats_saccade_df.to_csv(output_file_name_2, index=False)\n",
    "\n",
    "# print('Fixation statistics saved to', output_file_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
